# Proyecto Abejas — Segmentación con Ultralytics YOLO

Este README reúne **toda la documentación** para preparar el entorno, dividir el dataset, entrenar, validar y predecir **segmentación** con YOLO (Ultralytics), además de scripts de utilidad y un **script interactivo** para entrenar/predicciones.

---

## Índice

1. [Requisitos y entorno](#1-requisitos-y-entorno)
2. [Estructura de datos y formato de etiquetas](#2-estructura-de-datos-y-formato-de-etiquetas)
3. [Dividir el dataset (train/valid/test)](#3-dividir-el-dataset-trainvalidtest)
4. [Script interactivo de entrenamiento y predicción](#4-script-interactivo-de-entrenamiento-y-predicción)
5. [Entrenar y validar](#5-entrenar-y-validar)
6. [Pruebas sobre **test** y guardado de imágenes](#6-pruebas-sobre-test-y-guardado-de-imágenes)
7. [Visualizar GT vs Pred en Jupyter (overlay + IoU rápido)](#7-visualizar-gt-vs-pred-en-jupyter-overlay--iou-rápido)
8. [Cálculo de áreas de polígonos](#8-cálculo-de-áreas-de-polígonos)
9. [Verificación visual de recortes y polígonos](#9-verificación-visual-de-recortes-y-polígonos)
10. [Buenas prácticas](#10-buenas-prácticas)
11. [Comandos rápidos](#11-comandos-rápidos)

---

## 1) Requisitos y entorno

### Activar el ambiente virtual
```bash
# Alias conveniente (si existe en tu shell)
act bb

# Si no existe el alias, activa manualmente el entorno:
source /home/gomosak/ambientes/bb/bin/activate
```

### (Opcional) Instalar JupyterLab y crear kernel del entorno
> Útil si vas a experimentar desde notebooks.
```bash
pip install jupyterlab ipykernel
python -m ipykernel install --user --name=bb --display-name "Python (bb)"
jupyter lab
```

### Instalar dependencias principales
```bash
pip install ultralytics opencv-python matplotlib numpy
```

> **Nota**: Si usas segmentación, prefiere pesos `*-seg.pt` (p. ej. `yolo11n-seg.pt`).


---

## 2) Estructura de datos y formato de etiquetas

Estructura esperada (ejemplo):
```
abejas_segmentation/
 ├── train/
 │   ├── images/
 │   └── labels/
 ├── valid/
 │   ├── images/
 │   └── labels/
 └── test/
     ├── images/
     └── labels/
```

- Las **etiquetas** están en formato **YOLO-seg** (segmentación):  
  Cada línea representa **una instancia** (objeto) en la imagen:
  ```
  <clase> x1 y1 x2 y2 ... xN yN
  ```
  donde `x, y` están **normalizados** en `[0,1]` respecto al ancho/alto.

- En este proyecto hay **una sola clase** (lo no anotado es **fondo**).  
  En `data.yaml` define solo esa clase:
  ```yaml
  path: /home/gomosak/abejas/abejas_segmentation
  train: train/images
  val: valid/images
  test: test/images
  names:
    0: objeto
  ```

---

## 3) Dividir el dataset (train/valid/test)

Script: `segmentation_dataset.py`

### Uso genérico
```bash
python segmentation_dataset.py \
  --images-dir /path/to/images \
  --labels-dir /path/to/labels \
  --output-base output/path \
  --train 0.7 --valid 0.2 --test 0.1 \
  --frame-class 1 --target-class 0 \
  --seed 42 --log-level INFO
```

### Ejemplo con rutas del proyecto
```bash
python segmentation_dataset.py \
  --images-dir /home/gomosak/abejas/abejas/images \
  --labels-dir /home/gomosak/abejas/abejas/labels \
  --output-base /home/gomosak/abejas/abejas_segmentation \
  --train 0.7 --valid 0.2 --test 0.1 \
  --frame-class 1 --target-class 0 \
  --seed 42 --log-level INFO
```

**Qué hace**:
- Lee imágenes desde `abejas/images/` y labels desde `abejas/labels/`.
- Recorta cada imagen según el **marco (clase 1)** y reproyecta/clippea los **polígonos (clase 0)**.
- Divide en `train/valid/test` con las proporciones indicadas.
- Asegura correspondencia nombre-imagen/nombre-etiqueta.

---

## 4) Script interactivo de entrenamiento y predicción

Archivo sugerido: `yolo_interactive.py`  
Ejecuta un flujo **interactivo** para **TRAIN** o **PREDICT** en segmentación.

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Interactive YOLO pipeline script.

- Asks whether to TRAIN or PREDICT
- Prompts for model, dataset, and output paths
- Runs the chosen task using Ultralytics YOLO interface

Requirements:
    pip install ultralytics
"""

import os
from ultralytics import YOLO

def ask(msg: str, default: str | None = None) -> str:
    """Prompt with optional default."""
    if default:
        msg = f"{msg} [{default}]: "
    else:
        msg = f"{msg}: "
    val = input(msg).strip()
    return val if val else (default or "")

def do_train():
    print("\n=== TRAIN MODE ===")
    model_path = ask("Path to model (.pt)", "yolo11n-seg.pt")
    data_yaml = ask("Path to dataset YAML", "/home/gomosak/abejas/abejas_segmentation/data.yaml")
    epochs = int(ask("Number of epochs", "100"))
    imgsz = int(ask("Image size", "640"))

    print("\nStarting training...")
    model = YOLO(model_path)
    model.train(
        data=data_yaml,
        epochs=epochs,
        imgsz=imgsz
    )
    print("\n✅ Training finished.")

def do_predict():
    print("\n=== PREDICT MODE ===")
    model_path = ask("Path to trained model (.pt)", "/home/gomosak/abejas/runs/segment/train/weights/best.pt")
    source = ask("Source directory or file", "/home/gomosak/abejas/abejas_segmentation/test/images")
    project = ask("Project output folder", "/home/gomosak/abejas/outputs")
    name = ask("Experiment name", "test_predict")
    conf = float(ask("Confidence threshold", "0.25"))
    iou = float(ask("IoU threshold", "0.7"))

    print("\nStarting prediction...")
    model = YOLO(model_path)
    model.predict(
        source=source,
        task="segment",
        save=True,
        conf=conf,
        iou=iou,
        project=project,
        name=name,
        exist_ok=True
    )
    print("\n✅ Prediction finished. Results saved in:", os.path.join(project, name))

def main():
    print("YOLO Interactive Script")
    choice = ask("Do you want to [train] or [predict]?", "train").lower()

    if choice.startswith("t"):
        do_train()
    elif choice.startswith("p"):
        do_predict()
    else:
        print("❌ Invalid choice. Please run again and select 'train' or 'predict'.")

if __name__ == "__main__":
    main()
```

### Requisitos
```bash
act bb   # o: source /home/gomosak/ambientes/bb/bin/activate
pip install ultralytics
```

### Ejecución
```bash
python yolo_interactive.py
```

---

## 5) Entrenar y validar

### Entrenar (CLI)
```bash
yolo train task=segment \
  model=yolo11n-seg.pt \
  data=/home/gomosak/abejas/abejas_segmentation/data.yaml \
  epochs=100 imgsz=640
```

### Entrenar (Python/Jupyter)
```python
from ultralytics import YOLO
model = YOLO("yolo11n-seg.pt")
model.train(data="/home/gomosak/abejas/abejas_segmentation/data.yaml",
            epochs=100, imgsz=640)
```

### Validación (usa `val` split por defecto del `data.yaml`)
```bash
yolo val task=segment \
  model=/home/gomosak/abejas/runs/segment/train/weights/best.pt \
  data=/home/gomosak/abejas/abejas_segmentation/data.yaml \
  imgsz=640 save=True save_txt=True save_json=True \
  conf=0.25 iou=0.7
```

Resultados: `runs/segment/val*` (métricas, curvas, mosaicos `val_batch*_pred.jpg`, predicciones `.txt` en `labels/`).

---

## 6) Pruebas sobre **test** y guardado de imágenes

### Métricas sobre **test** (usa las GT de `labels/test`)
```bash
yolo val task=segment \
  model=/home/gomosak/abejas/runs/segment/train/weights/best.pt \
  data=/home/gomosak/abejas/abejas_segmentation/data.yaml \
  split=test imgsz=640 \
  save=True save_txt=True save_json=True \
  conf=0.25 iou=0.7
```

> `val` en test **guarda mosaicos** por batch + predicciones en `.txt` y calcula métricas.

### **Imágenes por archivo** (predicción/visualización)
Para obtener una **imagen de salida por cada imagen** de test, usa `predict`:

```bash
yolo predict task=segment \
  model=/home/gomosak/abejas/runs/segment/train/weights/best.pt \
  source=/home/gomosak/abejas/abejas_segmentation/test/images \
  save=True conf=0.25 iou=0.7 \
  project=/home/gomosak/abejas/outputs name=test_predict exist_ok=True
```

Las imágenes se guardan en:  
`/home/gomosak/abejas/outputs/test_predict/`

---

## 7) Visualizar GT vs Pred en Jupyter (overlay + IoU rápido)

```python
from pathlib import Path
import numpy as np, cv2, matplotlib.pyplot as plt

def yolo_poly_to_abs(xy_norm, w, h):
    xy = np.array(xy_norm, dtype=np.float32).reshape(-1, 2)
    return np.stack([xy[:,0]*w, xy[:,1]*h], axis=1).astype(np.int32)

def load_yolo_poly_txt(txt_file):
    polys = []
    p = Path(txt_file)
    if not p.exists(): return polys
    for line in p.read_text().strip().splitlines():
        parts = line.strip().split()
        if len(parts) < 3: continue
        cls = int(parts[0])
        coords = list(map(float, parts[1:]))
        if len(coords) % 2 != 0: continue
        polys.append((cls, coords))
    return polys

def rasterize_mask(shape, polys_abs):
    mask = np.zeros(shape[:2], dtype=np.uint8)
    for pa in polys_abs:
        cv2.fillPoly(mask, [pa], 1)
    return mask

DATA = Path("/home/gomosak/abejas/abejas_segmentation")
img_dir = DATA/"test/images"
gt_dir  = DATA/"test/labels"
# Ajusta al último val*
val_dir = sorted((Path("/home/gomosak/abejas/runs/segment")).glob("val*"), key=lambda p: p.stat().st_mtime)[-1]
pred_dir = val_dir / "labels"

img_path = sorted(img_dir.glob("*.*"))[0]  # cambia índice si quieres otra imagen
stem = img_path.stem
gt_txt, pred_txt = gt_dir/f"{stem}.txt", pred_dir/f"{stem}.txt"

img = cv2.imread(str(img_path))[:, :, ::-1]
h, w = img.shape[:2]

# Cargar polígonos GT y Pred
gt_polys = [yolo_poly_to_abs(coords, w, h) for _, coords in load_yolo_poly_txt(gt_txt)]
pr_polys = [yolo_poly_to_abs(coords, w, h) for _, coords in load_yolo_poly_txt(pred_txt)]

# Overlay
vis = img.copy()
for pa in gt_polys:
    cv2.polylines(vis, [pa], True, (0,255,0), 2)
    cv2.fillPoly(vis, [pa], (0,255,0))
for pa in pr_polys:
    cv2.polylines(vis, [pa], True, (255,0,0), 2)

plt.figure(figsize=(8,8)); plt.title(f"GT (verde) vs Pred (rojo): {stem}")
plt.imshow(vis); plt.axis('off'); plt.show()

# IoU global de máscara
gt_mask = rasterize_mask(img, gt_polys)
pr_mask = rasterize_mask(img, pr_polys)
inter = np.logical_and(gt_mask==1, pr_mask==1).sum()
union = np.logical_or(gt_mask==1, pr_mask==1).sum()
iou = inter / union if union > 0 else 0.0
print(f"IoU de máscara (global): {iou:.3f}")
```

---

## 8) Cálculo de áreas de polígonos

Script: `area.py`  
Convierte coordenadas normalizadas a pixeles y calcula áreas (ej. fórmula de Shoelace).

```bash
python area.py
```

---

## 9) Verificación visual de recortes y polígonos

Script: `verification_polygons.py`  
Muestra la imagen original con anotaciones y el recorte por **marco (clase 1)** con polígonos re-proyectados. En entornos sin GUI, puede guardar las imágenes de verificación a disco.

```bash
python verification_polygons.py
```

---

## 10) Buenas prácticas

- Mantén **nombres de archivo** consistentes entre imágenes y etiquetas (`img.jpg` ↔ `img.txt`).
- Coordenadas siempre **normalizadas** `[0,1]` en etiquetas YOLO-seg.
- Una **línea por instancia** en cada `.txt`.
- Para segmentación de **una sola clase**, no definas “fondo” como clase; todo lo no anotado es BG.
- Controla versiones de entorno (usa tu venv `bb`) y fija **semillas** si necesitas reproducibilidad.
- Si entrenas desde `yaml` de arquitectura (desde cero), espera más epochs para convergencia.

---

## 11) Comandos rápidos

```bash
# Activar entorno
act bb

# Entrenar
yolo train task=segment model=yolo11n-seg.pt \
  data=/home/gomosak/abejas/abejas_segmentation/data.yaml \
  epochs=100 imgsz=640

# Validar en val (default) o en test (split=test)
yolo val task=segment \
  model=/home/gomosak/abejas/runs/segment/train/weights/best.pt \
  data=/home/gomosak/abejas/abejas_segmentation/data.yaml \
  split=test imgsz=640 save=True save_txt=True save_json=True conf=0.25 iou=0.7

# Predicción (una imagen de salida por archivo)
yolo predict task=segment \
  model=/home/gomosak/abejas/runs/segment/train/weights/best.pt \
  source=/home/gomosak/abejas/abejas_segmentation/test/images \
  save=True conf=0.25 iou=0.7 \
  project=/home/gomosak/abejas/outputs name=test_predict exist_ok=True
```

---

> **Contacto/Notas**: Si cambias la estructura de carpetas o los nombres, ajusta las rutas de `data.yaml` y de los comandos del README en consecuencia.